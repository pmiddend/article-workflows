* Musings on UIs, familiarity and workflows

** Source material 1: Intuitive Equals Familiar

 INTUITIVE EQUALS FAMILIAR  
   
 By Raskin, J.  
   
 One of the most common terms of praise for an interface is to say that it is "intuitive"  
 (the word should have been "intuitable" but we will bow to convention). Yet the Human  
 Computer Interaction (HCI) literature rarely mentions the word, and for good reason.  
 This note attempts to clarify the meaning of "intuitive" for non-HCI specialists.  
   
 The impression that the phrase "this interface feature is intuitive" leaves is that the  
 interface works the way the user does, that normal human "intuition" suffices to use it,  
 that neither training nor rational thought is necessary, and that it will feel "natural."  
 We are said to "intuit" a concept when we seem to suddenly understand it without any  
 apparent effort or previous exposure to the idea. In common parlance, intuition has the  
 additional flavor of a nearly supernatural ability humans possess in varying degrees.  
 Given these connotations, it is as uncomfortable a term in formal HCI studies as it is a  
 common one in non-technical publications and in informal conversation about  
 interfaces.  
   
 As I learned from a talk given by Martin Marshall in Palo Alto (at the May 94  
 BayCHI meeting), a number of commercial magazine-related "usability" labs that rate  
 software qualities give 50% of their weighting to User Satisfaction, 30% to  
 Productivity, and 20% to Intuitiveness. "Intuitiveness" in this context is considered to  
 be a function of percentage of tasks completed and the number of help references  
 made while in the very early stages of using a product.  
   
 There are occasional hints of the meaning of "intuitive" in the literature. Stephen  
 Oppenheimer, of the Review Board of InfoWorld magazine, noted in his review of  
 Mathcad 4.0 that "The editing tools become increasingly intuitive over time." Similarly,  
 Richard Collins in Flying (October 1994 pg. 67), speaking of a new aircraft navigation  
 device, "Like anything, it can be learned, but it would take a lot of experience to do it  
 intuitively." These uses of the term are uncharacteristic in that immediacy is normally  
 an important aspect of "intuition". In the usual sense of the word, something cannot  
 become intuitive over time, it is either intuitive or it is not. What Oppenheimer is  
 discussing is not intuition, but learning. When the tools had been learned, he is  
 saying, they became intuitive. This is a strong clue as to the meaning of "intuitive."  
   
 Many claims of intuitiveness, when examined, fail. It has been claimed that the use of a  
 computers mouse is intuitive. Yet it is far from that. In one of the Star Trek series  
 of science fiction movies, the space ships engineer has been brought back into our  
 time, where (when) he walks up to a Macintosh. He picks up the mouse, bringing it to  
 his mouth as if it were a microphone, and says: "Computer, ..." The audience laughs at  
 his mistake.  
   
 But that is just the whimsy of a screenwriter. Or is it? I performed a deliberate  
 experiment some years ago using one of the early Apple Macintosh computers. I  
 loaded a childrens program, The Manhole, where user interaction is strictly (and  
 cleverly) limited to "clicking" on various places on an image. Clicking consists of  
 moving the cursor to some location on the screen by moving the mouse on a surface  
 and momentarily pressing the only button on the mouse. Clicking on certain places  
 yields a new screen. This cold description does not express the delight most people  
 find in running The Manhole program, but that is not relevant here.  
   
 My subject was an intelligent, computer-literate, university-trained teacher visiting from  
 Finland who had not seen a mouse or any advertising or literature about it. With the  
 program running, I pointed to the mouse, said it was "a mouse", and that one used it to  
 operate the program. Her first act was to lift the mouse and move it about in the air.  
 She discovered the ball on the bottom, held the mouse upside down, and proceeded to  
 turn the ball. However, in this position the ball is not riding on the position pick-offs  
 and it does nothing. After shaking it, and making a number of other attempts at finding  
 a way to use it, she gave up and asked me how it worked. She had never seen  
 anything where you moved the whole object rather than some part of it (like the  
 joysticks she had previously used with computers): it was not intuitive. She also did  
 not intuit that the large raised area on top was a button.  
   
 But once I pointed out that the cursor moved when the mouse was moved on the  
 desks surface and that the raised area on top was a pressable button, she could  
 immediately use the mouse without another word. The directional mapping of the  
 mouse was "intuitive" because in this regard it operated just like joysticks (to say  
 nothing of pencils) with which she was familiar.  
   
 From this and other observations, and a reluctance to accept paranormal claims  
 without repeatable demonstrations thereof, it is clear that a user interface feature is  
 "intuitive" insofar as it resembles or is identical to something the user has already  
 learned. In short, "intuitive" in this context is an almost exact synonym of "familiar."  
   
 Given this insight, the measure of intuitiveness used by the magazine usability labs is  
 logical. The percentage of tasks completed increases with increasing intuitiveness  
 since it simply means that the user is already at least partially trained with respect to  
 the feature or set of features under test. Training tends to decrease the time required  
 for task completion, especially at first. Similarly, the number of times the user has to  
 reference help screens increases with decreasing intuitiveness, that is, decreasing  
 familiarity. If the word "intuitive" is replaced by the more readily understood word  
 "familiar" the criterion the magazines have established with respect to intuitiveness  
 seems obvious.  
   
 The term "intuitive" is associated with approval when applied to an interface, but this  
 association and the magazines rating systems raise the issue of the tension  
 between improvement and familiarity. As an interface designer I am often asked to  
 design a "better" interface to some product. Usually one can be designed such that, in  
 terms of learning time, eventual speed of operation (productivity), decreased error  
 rates, and ease of implementation it is superior to competing or the clients own  
 products. Even where my proposals are seen as significant improvements, they are  
 often rejected nonetheless on the grounds that they are not intuitive. It is a classic  
 "catch 22." The client wants something that is significantly superior to the  
 competition. But if superior, it cannot be the same, so it must be different (typically the  
 greater the improvement, the greater the difference). Therefore it cannot be intuitive,  
 that is, familiar. What the client usually wants is an interface with at most marginal  
 differences that, somehow, makes a major improvement. This can be achieved only on  
 the rare occasions where the original interface has some major flaw that is remedied  
 by a minor fix.  
   
 The present rating systems of the magazines and the similar thinking of many users,  
 managers, and marketers about products with significant human interface components  
 serves to preserve the status quo, even when it can be shown that a feature that is  
 completely familiar (intuitive) is deficient. This tendency makes it more difficult for  
 major advances in human interfaces to achieve commercial realization. When I am able  
 to present the argument given here that intuitive = familiar, I find that  
 decision-makers are often more open to new interface ideas.  
   
 I suggest that we replace the word "intuitive" with the word "familiar" (or sometimes  
 "old hat") in informal HCI discourse. HCI professionals might prefer another phrase:  
   
 Intuitive = uses readily transferred, existing skills.  
   
 It would read very differentlyand more honestlyif the magazines discussed  
 above made it clear that ratings were based, for example, 50% on user satisfaction,  
 30% on productivity, and 20% on familiarity. Note that user satisfaction and early  
 productivity (long-term productivity, though of great importance to users, is not  
 tested) are strongly dependent on familiarity, so that the rating system is further  
 flawed in not being built on a set of independent (orthogonal) bases: the three  
 parameters tend to rise and fall together.  
   
 That quality of a new interface paradigm that is commonly titled "intuitive" may well  
 turn out to be one of the worst qualities it can have.  
 
** Introduction

Let me start with an introduction to what the hell I’m talking about, for /everybody/, not just the hard-core emacs-and-Linux geeks: Graphical user interfaces are based on the concept of a /window/[fn:1]. An application can open zero one or more windows to display stuff to the user. Notepad on Windows, for example, displays one main window to show what you’re editing, and possibly other windows for things like “Save file” dialogs.

In fact, let’s stick with Notepad for a minute longer. If you’re using Microsoft Windows right now, go on, fire up Notepad (if not, /imagine/ you do). Done? Okay, do it again. And again. What do you see? Probably something like this:

/insert cascading notepads here/

Let’s figure how we got here. The first notepad was started and it created a new window, somewhere “in the middle” of the screen. The next Notepad you ran also created a window, and decided to arrange itself so it doesn’t completely obscure the previous Notepad. And so on, giving us this nice little cascading effect.

You can imagine that this cascading effect isn’t something built into Notepad. It’s more a “whole of Microsoft Windows” thing than a Notepad thing. In fact, when an applications wants to create a window, it doesn’t have to decide /where/ or even /how big/ that window should be. It can just…not care, and the operating system (OS) will deliver something. Even if the application /wishes/ for a window with a specific size or position, the operating system can /still/ be mean and give it /something else/!

The lesson here is: creating and managing windows ultimately isn’t controlled by the application but by the operating system. Now, an operating system does a lot of things. Managing devices, saving power on battery, decoding network packages. None of these are the topic of this article. To simplify things in our heads, let’s imagine a /separate/ system whose only responsibility is to manage windows. And let’s call it the Window Manager, or WM for short.

This separate system runs in the background and receives /requests/ by applications. Like “Hey, I’d like a window that’s 300x200 pixels, place it wherever you have space left.”, or “You know that window called ‘print dialog’ I created like, 5 minutes ago? I’m done with that, close it please.”. It also receives requests from other sources, like “The mouse wants to drag this window around - move it!” or “Monitor 2 was just unplugged”.

** The Rift

The thing with Window Managers is: they break down Operating Systems into two categories: Those that have more than one Window Manager and those that don’t. And this is where it gets interesting. Here’s a little table visualizing that difference:

| Operating System | Number of WMs available |
|------------------+-------------------------|
| Windows          | 1                       |
| Mac OS           | 1                       |
| Linux            | a gazillion             |
| Android          | 1, probably?            |
| OSX              | 1, probably?            |

Huh, what’s that spike in the middle there, a gazillion WMs, you say? How come?

Well, the thing about Linux is, you can’t have just “Linux” installed. I mean, you could. And all your devices, mouse, keyboard, screen, would still work. But there would be no way to use them. That’s because Linux is really just a bunch of drivers, sitting there, getting input from the outside world, being ready for some applications to process that input. However, no applications, no fun.

That’s why every Linux system is like that crate of Legos you had when you were a kid. You get it out, and /ex nihilo/, you build something. A skyscraper, a space station, a piece of toast. The sky’s the limit.

/image of a crate of legos/

And just like with Legos, you aren’t really /productive/ with them. You just experiment, and from time to time, you build cool stuff out of the components and the experience you have amassed.

So, on top of this bare Linux thingy, people built software to draw pretty pixels with. And later on, they added the ability to run more than one application at the same time. Then, the Linux guys figured they might adopt this concept of windows to visualize all the pixely applications running at the same time.

But they were still Lego guys, so they made the system managing these windows (the WM) a Lego block they could swap out and experiment with. One of the first WMs on Linux was “twm”, and it’s still around. Enabling it and starting some applications, this is how it looked:

/screenshot of twm and some windows from Wikipedia/

It definitely has this “eighties” feel to it. And you can see that a Linux system can look quite different than a Windows or MacOS system (notice the lack of a Start Bar or Dock).

[fn:1] Yes, Xorg might call windows something different, and emacs, too, but I think everybody gets and knows that word.

** The Hierarchy of Window Managers

The question that’s probably on your mind right now is: what’s out there? I mean, what do these gazillion WMs do different?

